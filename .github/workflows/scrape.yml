name: Hourly RSS scrape

on:
  schedule:
    - cron: '0 * * * *'  # 每小時整點
  workflow_dispatch: {}

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies & diagnostics
        run: |
          echo "*** Runner info ***"
          uname -a
          python --version
          which python || true
          echo "*** pip freeze before install ***"
          pip freeze | sed -n '1,200p' || true

          python -m pip install --upgrade pip
          pip install -r requirements.txt

          echo "*** Playwright install via Python (no npx needed) ***"
          # 使用 python 的 playwright CLI，避免缺少 npx/node 的情況
          python -m playwright install --with-deps || (echo "playwright install failed" && exit 1)

      - name: Run scraper
        env:
          OUTPUT_DIR: docs
          SKIP_INDEX: 'true'  # index 手動更新
        run: |
          python scraper.py

      - name: Commit and push changes (if any)
        env:
          GIT_COMMITTER_NAME: "github-actions[bot]"
          GIT_COMMITTER_EMAIL: "41898282+github-actions[bot]@users.noreply.github.com"
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            git config user.name "$GIT_COMMITTER_NAME"
            git config user.email "$GIT_COMMITTER_EMAIL"
            git add docs/*.xml || true
            git add docs/index.html || true
            git commit -m "Automated: update RSS outputs" || echo "no changes to commit"
            git push
          else
            echo "No changes to commit."
          fi
